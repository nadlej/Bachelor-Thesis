{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_first_model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3k40trwvWbf"
      },
      "source": [
        "!pip3 install pickle5\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sn\n",
        "import pickle5 as pickle\n",
        "from datetime import datetime \n",
        "from pylab import savefig\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive \n",
        "from numpy import load, save\n",
        "from keras import regularizers, activations\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygsq4F631tLj"
      },
      "source": [
        "Importowanie bibliotek."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf-qSwrrvnLa",
        "outputId": "282606a1-4254-4016-b51c-e27570c5091a"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "us8k_df = pd.read_pickle(\"/content/gdrive/MyDrive/Licencjat/us8k_df.pkl\")\n",
        "\n",
        "sound_classes_short = ['WEN', 'KLAK', 'DZIE', 'PIES', 'WIER',\n",
        "                      'SIL', 'STRZ', 'MŁOT', 'SYR', 'UL']                     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qFON7T2112R"
      },
      "source": [
        "Połaczenie z Google Drive'm oraz wczytanie pliku w formacie \"pickle\" zawierającym zapis spektrogramów przeskalowanych w skali melowej wraz z odpowiadającymi oznaczeniami folderów i klas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Nmzda3Cm8Y6V",
        "outputId": "3fe33804-7ac7-41a0-b5db-227908c58310"
      },
      "source": [
        "us8k_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>melspectrogram</th>\n",
              "      <th>audio_class_id</th>\n",
              "      <th>folder_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-62.043755, -78.71548, -66.24806, -65.44084,...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-10.453897, -2.5422764, -11.506107, -12.6137...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-23.941132, -14.804116, -6.170871, -12.02620...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-15.381372, -12.846268, -13.1903305, -12.138...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-9.8033905, 0.0, -10.955839, -9.584627, -5.0...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      melspectrogram  audio_class_id folder_id\n",
              "0  [[-62.043755, -78.71548, -66.24806, -65.44084,...               3         5\n",
              "1  [[-10.453897, -2.5422764, -11.506107, -12.6137...               2         5\n",
              "2  [[-23.941132, -14.804116, -6.170871, -12.02620...               2         5\n",
              "3  [[-15.381372, -12.846268, -13.1903305, -12.138...               2         5\n",
              "4  [[-9.8033905, 0.0, -10.955839, -9.584627, -5.0...               2         5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtxjkWew2iV5"
      },
      "source": [
        "Budowa architektury modelu bazowego."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWxUVMy3v09q"
      },
      "source": [
        "def init_model():\n",
        "    model1 = Sequential()\n",
        "    \n",
        "    #layer-1\n",
        "    model1.add(Conv2D(filters=24, kernel_size=5, input_shape=(128, 128, 1)))\n",
        "    model1.add(MaxPooling2D(pool_size=(4,2)))\n",
        "    model1.add(Activation(activations.relu))\n",
        "    \n",
        "    #layer-2\n",
        "    model1.add(Conv2D(filters=48, kernel_size=5))\n",
        "    model1.add(MaxPooling2D(pool_size=(4,2)))\n",
        "    model1.add(Activation(activations.relu))\n",
        "    \n",
        "    #layer-3\n",
        "    model1.add(Conv2D(filters=48, kernel_size=5))\n",
        "    model1.add(Activation(activations.relu))\n",
        "    \n",
        "    model1.add(Flatten())\n",
        "    \n",
        "    #layer-4 \n",
        "    model1.add(Dropout(0.5))\n",
        "    model1.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    #layer-5\n",
        "    model1.add(Dropout(0.5))\n",
        "    model1.add(Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # compile\n",
        "    model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))\n",
        "    \n",
        "    return model1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DwddSpl2l7R"
      },
      "source": [
        "Inicjalizacja modelu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmweAM9t-N5-"
      },
      "source": [
        "model = init_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vliwIodx2r6E"
      },
      "source": [
        "Funkcja dzielenia folderów na zbior walidacyjny, testowy oraz treningowy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq_r3J6zyBhC"
      },
      "source": [
        "def train_test_split(fold_k, data, X_dim=(128, 128, 1)):\n",
        "  train_set = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
        "  train_set.remove(fold_k)\n",
        "  val_fold = random.choice(train_set)\n",
        "  \n",
        "  X_train = data[data.folder_id != val_fold]\n",
        "  X_train = np.stack(X_train[X_train.folder_id != fold_k].melspectrogram.to_numpy())\n",
        "  X_val = np.stack(data[data.folder_id == val_fold].melspectrogram.to_numpy())\n",
        "  X_test = np.stack(data[data.folder_id == fold_k].melspectrogram.to_numpy())\n",
        "\n",
        "  y_train = data[data.folder_id != fold_k]\n",
        "  y_train = y_train[y_train.folder_id != val_fold].audio_class_id.to_numpy()\n",
        "  y_val = data[data.folder_id == val_fold].audio_class_id.to_numpy()\n",
        "  y_test = data[data.folder_id == fold_k].audio_class_id.to_numpy()\n",
        "\n",
        "  XX_train = X_train.reshape(X_train.shape[0], *X_dim)\n",
        "  XX_val = X_val.reshape(X_val.shape[0], *X_dim)\n",
        "  XX_test = X_test.reshape(X_test.shape[0], *X_dim)\n",
        "  \n",
        "  yy_train = to_categorical(y_train)\n",
        "  yy_val = to_categorical(y_val)\n",
        "  yy_test = to_categorical(y_test)\n",
        "  \n",
        "  return XX_train, XX_val, XX_test, yy_train, yy_val, yy_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snZBCDMu240C"
      },
      "source": [
        "Funkcja zwracająca dokładność modelu dla danych testowych oraz macierz pomyłek dla tych danych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUG0iT5FYxaT"
      },
      "source": [
        "def evaluate(model, XX_test, yy_test):\n",
        "    y_prob = model.predict(XX_test, verbose=0)\n",
        "    y_pred = np.argmax(y_prob, 1)\n",
        "    y_true = yy_test\n",
        "    y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "    score, accuracy = model.evaluate(XX_test, yy_test, batch_size=100, verbose=0)\n",
        "\n",
        "    print(\"\\nDokładność = {:.2f}\".format(accuracy))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    return accuracy, cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZS5eQry3d9x"
      },
      "source": [
        "Funkcja rysująca wykres zmiany dokładności i straty w funkcji liczby epok."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubWbcLBWyuvy"
      },
      "source": [
        "def show_results(histories):\n",
        "    for i, history in enumerate(histories):\n",
        "        plt.figure(figsize=(15,5))\n",
        "\n",
        "        plt.subplot(121)\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.grid(linestyle='--')\n",
        "        plt.ylabel('Dokładność')\n",
        "        plt.xlabel('Epoka')\n",
        "        plt.legend(['train', 'validation'], loc='upper left')\n",
        "        plt.title(\"Dokładność modelu na epokę\")\n",
        "\n",
        "        plt.subplot(122)\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.grid(linestyle='--')\n",
        "        plt.ylabel('Strata')\n",
        "        plt.xlabel('Epoka')\n",
        "        plt.legend(['train', 'validation'], loc='upper left')\n",
        "        plt.title(\"Strata modelu na epokę\")\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "        print('\\tMaksymalna dokładność zbioru walidacyjnego: %.4f %%' % (np.max(history.history['val_accuracy']) * 100))\n",
        "        print('\\tMinimalna strata zbioru walidacyjnego: %.5f' % np.min(history.history['val_loss']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59a5nlBZ331p"
      },
      "source": [
        "Każdy folder po kolei jest wpisywany jako folder testowy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0KauOZwZYn0"
      },
      "source": [
        "TEST_FOLDER = '1'\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_test_split(TEST_FOLDER, us8k_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8LxEGr7WxwN"
      },
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oy6RcNI4z0T"
      },
      "source": [
        "Proces trenowania."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIUY78KDyvUB"
      },
      "source": [
        "history_store = []\n",
        "\n",
        "start = datetime.now()\n",
        "    \n",
        "history = model.fit(X_train, y_train, \n",
        "                    epochs=50,\n",
        "                    batch_size=100, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[EarlyStopping(restore_best_weights=True, patience=15)])\n",
        "end = datetime.now()\n",
        "history_store.append(history)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCO4AHud5JsT"
      },
      "source": [
        "Wyświetlanie rysunków."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CmwGOH1wtuR"
      },
      "source": [
        "show_results(history_store)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZVSjaSZ5NG5"
      },
      "source": [
        "Badanie dokładności dla danych testowych oraz zwrócenie macierzy pomyłek dla danego folderu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjSJdgMobltE",
        "outputId": "24afdbaa-f079-4290-d6bd-fecd8a055d98"
      },
      "source": [
        "accuracy, cm = evaluate(model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dokładność = 0.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w-zhYUA5Xco"
      },
      "source": [
        "Inicjalizowana jest zmienna \"CM\" oznaczająca macierz pomyłek. Zważając na to, że proces trenowania trwa chwilę, a trzeba go powtórzyć co najmniej 10 razy, macierz po zaktualizowaniu można zapisać, a następnie wczytać. Wówczas wykonywana jest jedynie część z następnych operacji - po zwróceniu macierzy pomyłek dla danego folderu, zapisanego w \"cm\" nie inicjalizujemy znowu \"CM\", a jedynie aktualizujemy jego wartości, dodając te z \"cm\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjzxO_UZfIxh"
      },
      "source": [
        "CM = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjRMmJ1Ye1d5"
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCN09fVSfXII"
      },
      "source": [
        "CM = CM + cm\n",
        "save('confusion_matrix.npy', CM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC32pY61w1Gi"
      },
      "source": [
        "CM = load('confusion_matrix.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwB-inhwfZEo"
      },
      "source": [
        "CM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vozoeLTP5Yt"
      },
      "source": [
        "Wyświetlenie macierzy pomyłek."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNZIdOI8Ph-l"
      },
      "source": [
        "df_cm = pd.DataFrame(CM, sound_classes_short, sound_classes_short)\n",
        "sn.set(font_scale=0.8)\n",
        "svm = sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 8},\n",
        "                 fmt=\".0f\", cbar_kws={'label': 'Liczba zaklasyfikowanych próbek'})\n",
        "plt.xlabel('Klasa prognozowana')\n",
        "plt.ylabel('Klasa rzeczywista')\n",
        "plt.figure(figsize = (20,14))\n",
        "figure = svm.get_figure()    \n",
        "figure.savefig('svm_conf.png', dpi=400)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac7_DDhzPOl3"
      },
      "source": [
        "Normalizacja wartości w macierzy pomyłek."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUvZUkFaf-Do"
      },
      "source": [
        "CM = load('confusion_matrix.npy')\n",
        "CM = CM.astype('float') / CM.sum(axis=1)[:, np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp0MRIaGEwFI"
      },
      "source": [
        "CM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wQ_4LOGP9GM"
      },
      "source": [
        "Wyświetlenie macierzy pomyłek dla macierzy znormalizowanej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax2LzV0nwkMo"
      },
      "source": [
        "df_cm = pd.DataFrame(CM, sound_classes_short, sound_classes_short)\n",
        "sn.set(font_scale=0.8)\n",
        "svm = sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 8},\n",
        "                 fmt=\".2f\", cmap=\"Blues\", cbar_kws={'label': 'Znormalizowana liczba zaklasyfikowanych próbek'})\n",
        "plt.xlabel('Klasa prognozowana')\n",
        "plt.ylabel('Klasa rzeczywista')\n",
        "plt.figure(figsize = (20,14))\n",
        "figure = svm.get_figure()    \n",
        "figure.savefig('svm_conf.png', dpi=400)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}